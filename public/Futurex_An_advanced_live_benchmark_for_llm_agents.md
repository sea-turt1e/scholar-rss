---
title: "【論文要約】 Futurex: An advanced live benchmark for llm agents in future prediction"
tags:
  - "機械学習"
  - "AI"
  - "論文"
  - "arXiv"
private: false
updated_at: ""
id: null
organization_url_name: null
slide: false
ignorePublish: false
---

## 論文情報

- **著者**: Z Zeng, J Liu, S Chen, T He, Y Liao, Y Tian
- **論文概要リンク**: https://arxiv.org/abs/2508.11987
- **論文PDFリンク**: https://arxiv.org/pdf/2508.11987?

## 要約

本論文は、大規模言語モデル（LLM）エージェントによる未来予測能力を評価するための初の大規模ライブベンチマーク「FutureX」を提案する。FutureXは195の多様な信頼性の高いウェブサイトから毎日未来予測に関する質問を自動収集し、LLMエージェントの予測と実際の結果をリアルタイムで比較評価する。25種類のモデルを対象にベンチマークを実施し、特に推論能力や検索能力を持つモデルが高い性能を示す一方、現状ではプロの人間アナリストと比較して依然として課題が多いことを示した。

## 主要なポイント

1. FutureXは未来予測に特化した世界最大かつ最も多様なライブベンチマークであり、データ汚染を根本的に排除しリアルタイム性を確保。
2. 難易度レベルを4段階に分けており、複雑かつ不確実性の高い問題では検索・推論能力を備えたエージェントが有利。
3. 現行の最先端モデルでもハードタスク（高変動・オープンエンド予測）では性能が大きく低下し、人間の専門家とは差がある。
4. フェイクニュースに対するモデルの脆弱性やリアルタイム情報の取得効率についての詳細分析も実施。
5. 今後のLLMエージェントの開発を促進するための動的で公平な評価基準を提供。


## メソッド

- **データ収集・管理**
AIMEエージェントによって2,008のウェブサイトから候補を収集し、LLMベースの自動フィルタリングと人手による高品質サイト選定で195サイトに絞る。
- **質問生成・操作**
予測マーケットからの二択・多択問題、ニュース・ランキング・統計サイトからのテンプレートを用いたオープンエンドな質問を日次で生成し、ランダム化・フィルタリング（不要・主観的・容易すぎる問題除外）を行う。
- **評価パイプライン**
質問のスタート日に25モデルに予測実行を依頼。決着日後に自動的にウェブクロールし正解を取得してモデル予測を採点。
- **モデル群**
基本LLM、検索・推論能力付きLLM、オープンソースDeep Research Agent、クローズドソースDeep Research Agentの4種25モデルを評価。
- **難易度区分**
レベル1（基礎単純）、レベル2（広範囲多択）、レベル3（安定オープンエンド）、レベル4（高変動オープンエンド）に分類し、それぞれ計画能力・推論・検索能力を異なる重みで評価。
- **評価指標**
単一択は正誤判定、多択はF1スコア、ランキングは部分一致スコア、数値予測は変動の標準偏差を基に点数化。

## 意義・影響

- FutureXはLLMエージェントの未来予測能力をリアルタイムかつ大規模に、公平かつ動的に評価する初のベンチマークであり、現実の専門家レベルを目指す研究の基盤を提供。
- データ汚染を防ぎ活きた問題で評価する仕組みは、従来の静的・過去データ利用型ベンチマークの限界を克服。
- 検索や推論強化の重要性を示し、将来のエージェント設計・改良の指針となる。
- フェイク情報耐性やリアルタイム情報活用の問題を浮き彫りにし、今後の安全性・信頼性研究の必要性を示唆。
- 金融予測など実務界との橋渡しとしても機能し、LLMの実用化促進に貢献。

---

以上の内容により、FutureXは未来予測タスクにおけるLLMエージェントの真の実力を試す最先端の評価基盤として大きなインパクトを持つ研究であると評価できる。


---
title: "【論文要約】 Who taught the lie? responsibility attribution for poisoned knowledge in retrieval-augmented generation"
tags:
  - "機械学習"
  - "AI"
  - "論文"
  - "arXiv"
private: false
updated_at: ""
id: null
organization_url_name: null
slide: false
ignorePublish: false
---

## 論文情報

- **著者**: B Zhang, H Xin, Y Chen, Z Liu, B Yi, T Li, L Nie
- **論文概要リンク**: https://arxiv.org/abs/2509.13772
- **論文PDFリンク**: https://arxiv.org/pdf/2509.13772

## 要約

この論文は、Retrieval-Augmented Generation（RAG）システムにおける知識ベースの汚染（ポイズニング）による誤生成の原因となるテキストの責任帰属問題に取り組んでいる。提案手法のRAGOriginは、ブラックボックス環境で各誤生成事象に対し責任対象テキストのスコアリングを行い、適応的に解析スコープを絞り込むことで、高精度かつ堅牢に汚染テキストを特定できることを示す。多数の攻撃手法や大規模データセットを用いた実験で、既存手法を大きく上回る性能を示し、実用的な応用可能性があることを明らかにした。

## 主要なポイント

1. RAGシステムは外部知識を取り込むが、知識ベースへの悪意あるテキストの注入に対して極めて脆弱である。
2. 既存の防御策は高度な攻撃に対して脆弱であり、ポイズニング後の責任帰属（誰が誤情報を教えたかの特定）が重要な課題となる。
3. RAGOriginは誤生成が起きた際に汚染テキストを特定するため、適応的に解析対象を絞り込み、埋め込み類似度と意味的相関、生成影響度の三つの指標を統合した責任スコアを用いる。
4. 15種類の多様なポイズニング攻撃や大規模データセットで評価し、既存の最先端手法を凌駕する精度と堅牢性を実証した。
5. 計算コストや金銭コストも現実的であり、商用や大規模運用に適した設計である。


## メソッド

### 1. 適応的な責任帰属スコープの絞り込み
- 知識ベース全体の中から、ユーザ質問との類似度に基づいて上位のテキスト群を段階的に抽出し、各段階の部分集合を用いて再度RAGの生成をシミュレーション。
- 生成した回答が誤生成と一致する部分集合を特定し、誤生成の原因となりうるテキストのスコープを適応的に確定。

### 2. 責任スコアリング
- **埋め込み類似度（ES）**：ユーザ質問の埋め込みとテキスト埋め込みの類似度。ポイズニングテキストは質問と高類似度になるよう最適化されている。
- **意味的相関（SC）**：プロキシLLMを用いてテキストを文脈とした上で質問トークン列の予測確率を測定し、意味的な関係性を評価。
- **生成影響度（GC）**：プロキシLLMを使用し、各テキスト単独での文脈提供時に誤生成回答が生成される確率を算出。

- 上記3指標をzスコア正規化後に平均して最終の責任スコアとし、これに基づきクラスタリングを用いてポイズニングテキストと通常テキストを分離。

### 3. 動的閾値決定
- 責任スコアの分布に対して2クラスのk-meansクラスタリングを行い、高スコア群をポイズニングテキストと判断。
- これにより攻撃状況に応じた閾値調整が不要で、異なる攻撃手法にも対応可能。

## 意義・影響

- RAGシステムの普及により、悪意ある知識汚染による誤情報生成リスクが増大する中、誤生成の責任帰属手法はセキュリティ・信頼性向上に不可欠となる。
- 本研究はブラックボックス環境にも対応し、実運用で困難なモデル内部情報へのアクセス不要で適用可能であるため、広範な現場利用が期待される。
- 多様かつ高度化する攻撃手法にも耐性を持ち、定量的に効果を示したことで、運用者がポイズニング発生源の特定、対策立案、攻撃追跡に活用可能。
- 将来の多段階対話やマルチモーダル型RAGシステムへの拡張も課題とし、次世代の安全な知識増強生成技術の発展に貢献。

---

参考までに、依頼文中の図表やアルゴリズムも含めて、論文本文から得たデータを総合してまとめました。必要に応じてさらに詳細な説明も対応可能です。

